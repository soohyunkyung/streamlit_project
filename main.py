import streamlit as st
import pandas as pd
import networkx as nx
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import altair as alt
from wordcloud import WordCloud
import os
import platform
import ast

# 1. í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ë¸”ë¡œê·¸ ë°ì´í„° ì‹œê°í™” ëŒ€ì‹œë³´ë“œ",
    page_icon="ğŸ“Š",
    layout="wide"
)

# 2. í°íŠ¸ ì„¤ì • (í•œê¸€ ê¹¨ì§ ë°©ì§€)
def get_font_family():
    system_name = platform.system()
    if system_name == "Windows":
        return "Malgun Gothic"
    elif system_name == "Darwin":
        return "AppleGothic"
    else:
        # ë¦¬ëˆ…ìŠ¤/ìŠ¤íŠ¸ë¦¼ë¦¿ í´ë¼ìš°ë“œ í™˜ê²½
        if os.path.exists('/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf'):
            return "NanumBarunGothic"
        return "sans-serif"

font_family = get_font_family()
plt.rcParams['font.family'] = font_family
plt.rcParams['axes.unicode_minus'] = False

# 3. ë°ì´í„° ë¡œë“œ í•¨ìˆ˜
@st.cache_data
def load_csv_data():
    try:
        # íŒŒì¼ ê²½ë¡œ ì„¤ì • (ê°™ì€ í´ë”ì— ìˆë‹¤ê³  ê°€ì •)
        df_wc = pd.read_csv('df_kdh.csv')           # ì›Œë“œí´ë¼ìš°ë“œìš©
        df_visu = pd.read_csv('df_kdh_visu.csv')    # ì°¨íŠ¸ìš© (Seaborn, Altair, Plotly)
        df_net = pd.read_csv('network_edge_list.csv') # ë„¤íŠ¸ì›Œí¬ìš©
        return df_wc, df_visu, df_net
    except FileNotFoundError as e:
        return None, None, None

st.title("ğŸ“‚ CSV ë°ì´í„° ê¸°ë°˜ ì‹œê°í™” ë¶„ì„")
st.markdown("---")

# ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
df_kdh, df_kdh_visu, df_network = load_csv_data()

# íŒŒì¼ì´ ì—†ì„ ê²½ìš° ê²½ê³  ë©”ì‹œì§€
if df_kdh is None:
    st.error("âš ï¸ CSV íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (df_kdh.csv, df_kdh_visu.csv, network_edge_list.csv íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤.)")
else:
    # ì‚¬ì´ë“œë°”: ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°
    with st.sidebar:
        st.header("ë°ì´í„° ìƒíƒœ")
        st.success("âœ… ë°ì´í„° ë¡œë“œ ì„±ê³µ")
        with st.expander("ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°"):
            st.write("WordCloudìš© ë°ì´í„°:", df_kdh.shape)
            st.write("Chartìš© ë°ì´í„°:", df_kdh_visu.shape)
            st.write("Networkìš© ë°ì´í„°:", df_network.shape)

    # íƒ­ êµ¬ì„±
    tab1, tab2, tab3 = st.tabs(["â˜ï¸ ì›Œë“œí´ë¼ìš°ë“œ", "ğŸ“Š í†µê³„ ì°¨íŠ¸ (3ì¢…)", "ğŸ•¸ï¸ ë„¤íŠ¸ì›Œí¬ ë¶„ì„"])

    # --- 1. WordCloud (df_kdh.csv) ---
    with tab1:
        st.header("WordCloud Analysis")
        
        # í…ìŠ¤íŠ¸ ë°ì´í„° ì¶”ì¶œ ë° ì „ì²˜ë¦¬
        # 'description_cleaned' ì»¬ëŸ¼ì´ ë¦¬ìŠ¤íŠ¸ ë¬¸ìì—´("['ë‹¨ì–´', 'ë‹¨ì–´']")ë¡œ ë˜ì–´ìˆì„ ê²½ìš° ì²˜ë¦¬
        if 'description_cleaned' in df_kdh.columns:
            target_col = 'description_cleaned'
        else:
            target_col = df_kdh.columns[0] # ì²«ë²ˆì§¸ ì»¬ëŸ¼ ì‚¬ìš©

        all_words = []
        sample_data = df_kdh[target_col].iloc[0]

        try:
            # ë¬¸ìì—´ í˜•íƒœì˜ ë¦¬ìŠ¤íŠ¸ì¸ì§€ í™•ì¸í•˜ê³  íŒŒì‹±
            if isinstance(sample_data, str) and sample_data.startswith('['):
                df_kdh[target_col] = df_kdh[target_col].apply(ast.literal_eval)
                for row in df_kdh[target_col]:
                    all_words.extend(row)
            else:
                # ì¼ë°˜ í…ìŠ¤íŠ¸ì¸ ê²½ìš°
                text_blob = " ".join(df_kdh[target_col].astype(str))
                all_words = text_blob.split()
            
            # ì›Œë“œí´ë¼ìš°ë“œ ê·¸ë¦¬ê¸°
            wc_font_path = '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf'
            if not os.path.exists(wc_font_path): wc_font_path = font_family

            wc = WordCloud(
                font_path=wc_font_path,
                background_color='white',
                width=1000, height=500,
                max_words=100
            ).generate_from_frequencies(pd.Series(all_words).value_counts())

            fig, ax = plt.subplots(figsize=(12, 6))
            ax.imshow(wc, interpolation='bilinear')
            ax.axis('off')
            st.pyplot(fig)
            
        except Exception as e:
            st.error(f"ì›Œë“œí´ë¼ìš°ë“œ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

    # --- 2. Charts: Seaborn, Altair, Plotly (df_kdh_visu.csv) ---
    with tab2:
        st.header("Keyword Frequency Visualization")
        
        # ì»¬ëŸ¼ëª… ìë™ ê°ì§€ (ì²«ë²ˆì§¸: ë‹¨ì–´, ë‘ë²ˆì§¸: ë¹ˆë„ë¼ê³  ê°€ì •)
        x_col_name = df_kdh_visu.columns[1] # ë¹ˆë„ (ìˆ«ì)
        y_col_name = df_kdh_visu.columns[0] # ë‹¨ì–´ (ë¬¸ì)
        
        # ìƒìœ„ 20ê°œë§Œ í•„í„°ë§
        df_chart = df_kdh_visu.sort_values(by=x_col_name, ascending=False).head(20)

        col_a, col_b = st.columns(2)
        
        # 2-1. Seaborn
        with col_a:
            st.markdown("### 1. Seaborn (Static)")
            fig_sb, ax_sb = plt.subplots(figsize=(8, 10))
            sns.barplot(data=df_chart, x=x_col_name, y=y_col_name, palette='viridis', ax=ax_sb)
            ax_sb.set_title("Seaborn Bar Plot")
            st.pyplot(fig_sb)

        # 2-2. Altair
        with col_b:
            st.markdown("### 2. Altair (Declarative)")
            chart_alt = alt.Chart(df_chart).mark_bar().encode(
                x=alt.X(f'{x_col_name}:Q', title='Frequency'),
                y=alt.Y(f'{y_col_name}:N', sort='-x', title='Keyword'),
                color=alt.Color(f'{x_col_name}:Q', scale=alt.Scale(scheme='tealblues')),
                tooltip=[y_col_name, x_col_name]
            ).properties(height=600, title="Altair Bar Chart")
            st.altair_chart(chart_alt, use_container_width=True)

        st.markdown("---")

        # 2-3. Plotly
        st.markdown("### 3. Plotly (Interactive)")
        fig_px = px.bar(
            df_chart, 
            x=x_col_name, 
            y=y_col_name, 
            orientation='h',
            title="Plotly Interactive Chart",
            color=x_col_name,
            color_continuous_scale='Viridis',
            height=600
        )
        fig_px.update_layout(yaxis={'categoryorder': 'total ascending'})
        st.plotly_chart(fig_px, use_container_width=True)

    # --- 3. NetworkX (network_edge_list.csv) ---
    with tab3:
        st.header("Keyword Network Analysis")
        
        # ì—£ì§€ ë¦¬ìŠ¤íŠ¸ ë¶ˆëŸ¬ì˜¤ê¸° (ì»¬ëŸ¼: Source, Target, Weight)
        if {'Source', 'Target', 'Weight'}.issubset(df_network.columns):
            
            # ì‚¬ìš©ì ì˜µì…˜
            col_opt1, col_opt2 = st.columns(2)
            with col_opt1:
                layout_mode = st.selectbox("ë ˆì´ì•„ì›ƒ ì•Œê³ ë¦¬ì¦˜", ["spring", "kamada_kawai", "circular"])
            with col_opt2:
                node_scale = st.slider("ë…¸ë“œ í¬ê¸° ë°°ìœ¨", 10, 100, 50)

            # ê·¸ë˜í”„ ìƒì„±
            G = nx.from_pandas_edgelist(df_network, source='Source', target='Target', edge_attr='Weight')
            
            # ë ˆì´ì•„ì›ƒ ê³„ì‚°
            if layout_mode == 'spring':
                pos = nx.spring_layout(G, k=0.5, iterations=50, seed=42)
            elif layout_mode == 'kamada_kawai':
                pos = nx.kamada_kawai_layout(G)
            else:
                pos = nx.circular_layout(G)

            # ì‹œê°í™”
            fig_net, ax_net = plt.subplots(figsize=(14, 14))
            
            # ë…¸ë“œ í¬ê¸° (Degree Centrality ê¸°ë°˜)
            d = dict(G.degree)
            node_sizes = [v * node_scale for v in d.values()]
            
            # ì—£ì§€ ë‘ê»˜ (Weight ê¸°ë°˜)
            weights = [G[u][v]['Weight'] for u,v in G.edges()]
            max_weight = max(weights) if weights else 1
            edge_widths = [(w / max_weight) * 3 for w in weights] # ìµœëŒ€ ë‘ê»˜ 3

            nx.draw_networkx_nodes(G, pos, node_size=node_sizes, node_color="skyblue", alpha=0.9, ax=ax_net)
            nx.draw_networkx_edges(G, pos, width=edge_widths, alpha=0.4, edge_color="gray", ax=ax_net)
            nx.draw_networkx_labels(G, pos, font_family=font_family, font_size=10, ax=ax_net)
            
            ax_net.set_title(f"Network Graph (Nodes: {len(G.nodes)}, Edges: {len(G.edges)})")
            ax_net.axis('off')
            st.pyplot(fig_net)
            
        else:
            st.error("CSV íŒŒì¼ ì»¬ëŸ¼ëª…ì´ ë§ì§€ ì•ŠìŠµë‹ˆë‹¤. (Source, Target, Weightê°€ í•„ìš”í•©ë‹ˆë‹¤)")
            st.write("í˜„ì¬ ì»¬ëŸ¼:", df_network.columns)
